\chapter{Inteligência artificial}\label{cap:ia} % ou aprendizado de máquina?
\section{Introdução}\label{sec:ia_intro}
A inteligência artificial é um amplo ramo que trata de sistemas capazes de aprender e interpretar informações, e usar esse aprendizado para objetivos específicos.
%TODO: citação haenlein
Um dos campos da inteligência artificial é o aprendizado de máquina, onde a unidade de computação aprende a performar uma tarefa a partir de um conjuntos de exemplos de treinamento,
%TODO: citação louridas
funcionando como um tipo de modelo computacional do cérebro. Esses modelos são construídos a partir da interconexão entre unidades de processamento, por vezes chamados de neurônios artificiais, e por isso são conhecidas como \textbf{redes neurais artificiais}.

O tipo mais comum de aprendizado de máquina é o chamado \textbf{aprendizado supervisionado}, onde o modelo é apresentado a um conjunto de dados de exemplo que são rotulados, ou seja, cada entrada tem a sua saída definida. Durante o aprendizado, o modelo fornece uma saída e, a partir da saída verdadeira, ele se ajusta internamente para se aproximar mais do real.
%TODO: citação lecun
Quando não há uma saída real rotulada disponível, pode-se utilizar o \textbf{aprendizado não-supervisionado}. Nesse caso, o modelo tenta aprender alguns padrões nos dados, como grupos de exemplos similares. O aprendizado não-supervisionado tem a capacidade de identificar novos tipos de informações, já que não estão restritos aos rótulos.
%TODO: citacao aniscar

Os algoritmos de aprendizado de máquina também podem ser divididos quanto à atividade a ser realizada. Atividades de \textbf{classificação} identificam a classe da informação (por exemplo, se um animal é um cão ou gato) a partir de dados rotulados, o \textbf{agrupamento} (\textit{clustering}, em inglês) determina classes agrupando informações similares em grupos (\textit{clusters}) rotulados (como o agrupamento de filmes em gêneros), a \textbf{regressão} é usada para prever algum valor ou quantidade (como o preço de ações ao longo do tempo), e a \textbf{redução de dimensionalidade} representa dados de várias dimensões em outras menores (como as várias informações de um paciente sendo reduzidas às mais importantes para o diagnóstico de uma doença).

\section{Redes neurais}\label{sec:redesneurais}
\begin{description}
	\item[Modelo de McCulloch\&Pitts] description
	\item[Perceptron] Primeiro modelo de neurônio artificial. É um classificador binário com uma função de ativação do tipo degrau
	\item[Perceptron de múltiplas camadas (MLP, \textit{Multilayer perceptron})] Combinação de vários neurônios do tipo perceptron em pelo menos três camadas: uma de entrada, uma oculta e uma de saída (Figura~\ref*{fig:modelosmlp}). Utiliza a técnica de aprendizado chamada \textit{backpropagation}, onde as atualizações dos pesos é feita da camada de saída em direção à de entrada. A grande maioria das redes neurais artificiais é derivada da MLP
	\item[Redes neurais profundas] Rede neural com uma grande quantidade de camadas ocultas. Alguns subtipos incluem as \textbf{Redes neurais recorrentes}, em que os dados fluem em qualquer direção, permitindo os neurônios enviarem \textit{feedback} uns para os outros (a rede Hopfield é uma delas), e as \textbf{Redes neurais convolucionais}, que aplicam uma operação de convolução e são bastante usadas em tarefas de visão computacional
	\item[Redes neurais de disparo (SNN, \textit{Spiking Neural Networks})] Redes onde a unidade computacional é um neurônio de disparo
\end{description}

\begin{figure}[htb!]
	\centering
	\caption[Modelos básicos de neurônios e redes neurais]{Modelos básicos de neurônios e redes neurais. Em (a), o perceptron com uma função de ativação do tipo degrau; em (b), o perceptron com uma função de ativação sigmoide; em (c), uma rede neural com uma camada oculta}
	\label{fig:modelosmlp}
	\includegraphics[width=0.9\linewidth]{figs/modelos_mlp}
\end{figure}


% backprop/grad desc

% lstm

\section{Redes neuromórficas}\label{sec:redesneuromorficas}
% estado da arte
% hardware neuromórfico (von-neumann vs neuromorfico)

\begin{itemize}
	\item Redes neurais de disparo usam neurônios de disparo como unidades de computação, como os modelos \textit{Leaky integrate-and-fire} (LIF) e o modelo de Izhikevich
	\item As unidades de computação são conectadas entre si e interagem através das sinapses (Figura~\ref{fig:sinapse})
\end{itemize}

\begin{figure}[htb!]
	\centering
	\caption[Neurônios pré e pós sinápticos conectados através de uma sinapse]{Neurônios pré (verde) e pós (roxo) sinápticos conectados através de uma sinapse. Os neurotransmissores (círculos vermelhos) são liberados do axônio pré-sinaptico para o dendrito pós-saptico, gerando potenciais pós-sinapticos que podem ser excitatórios (EPSP) ou inibitórios (IPSP). No neurônios pós-sinaptico os potenciais de todos os dendritos são somados e, dependendo do valor total, um potencial de ação (AP) pode ser gerado}
	\label{fig:sinapse}
	\includegraphics[width=0.3\linewidth]{figs/sinapse}
\end{figure}

\subsection{Processamento de informação}
\begin{itemize}
	\item A informação recebida pelas redes precisa ser codificada, e dois métodos para isso são:
	\begin{description}
		\item[Codificação de taxa] A taxa de disparo dos neurônios é usada. A taxa pode ser calculada como a média temporal (quantidade de disparos por intervalo de tempo), média de disparos em \textit{trials} diferentes, dentre outras maneiras
		\item[Codificação de tempo de disparo] O instante exato de ocorrência de disparos individuais é usado. Dentre os tipos de codificação nesse caso incluem-se o tempo do primeiro disparo (o tempo entre o início do estímulo e a ocorrência do primeiro disparo), a codificação de ordem (a ordem em que os neurônios disparam é o código), a codificação de latência (a diferença de tempo entre os disparos), dentre outras
	\end{description}
	\item Os critérios para seleção do método de codificação variam por diferentes aspectos, como a \textbf{minimização da perda de informação após a decodificação} e o \textbf{aumento da acurácia de previsão/classificação}
\end{itemize}

\subsection{Aprendizado das redes de disparo}
\begin{itemize}
	\item Para cada tipo de codificação citada acima, um método de aprendizado é empregado, que são:
	\begin{description}
		\item[Aprendizado baseado em taxa] Uma variação do método \textit{backpropagation} é usada aqui, relacionando as ativações das unidades das redes neurais com as taxas de disparo
		\item[Aprendizado baseado em disparo] Utiliza a plasticidade dependente de tempo de disparo (STDP, \textit{spike-timing dependent plasticity}),onde os pesos das conexões sinapticas são proporcionais ao grau de relação entre os tempos de disparo pré e pós-sinapticos (Figura~\ref{fig:stdp})
	\end{description}
\end{itemize}

\begin{figure}[htb!]
	\centering
	\caption{Conceito da STDP}
	\label{fig:stdp}
	\includegraphics[width=0.7\linewidth]{figs/stdp}
\end{figure}



% pensar onde colocar os simuladores
% \section{Simuladores neuronais}\label{sec:simuladores}
